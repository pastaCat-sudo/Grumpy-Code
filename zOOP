OOP:
This is a working file. It's informal and changes frequently...


PARSING - DEEP COMPREHENSION:
Parsing is translating grammar to action
(Less Movement to more Movement)     
It's about "Verbs" and the "Sequences" in which they occur.

Verbs -- are commands/words which will correspond to a direct execution.
Sequences -- are the result of the grammar's structure itself, and may also be imposed by delimiters/words.

Sequence Notes:
* The AST (Abstract Syntax Tree) derived from a grammar is implemented by the parser; finding the intermediary CPT (Concrete Parse Tree) is a useful initial step.
* If sequence delimiters happen to be words, then sometimes it's easy to mistake them for verbs! 
(E.g. "loop" or "for" don't directly correspond to an execution, but they will tell us how to repeat verbs).

We ultimately parse an input grammar to perform a series of executions. These executions are observed as an output. Outputs should be valid and meaningful.


PARSING IN PRACTISE:
The gross process of parsing is typically broken down into tokenization and then the parsing stage itself:
In my experience with smaller programs (that use tokenizers) the bare minimum a tokenizer must achieve is
to provide a set of tools to "identify" each relevant input token. Larger programs (with tokenizers) will 
use these tools to manipulate input further to reduce the burden placed on parsing.
The parser has two core roles. 1) It checks that the token sequence respects the structure of its grammar. 
2) It strips away delimiters/words from the CPT to form the AST; it may call execution methods
directly, or simply pass the AST format on for execution... 

Trival parsers may simply combine parsing roles.
In fact, scases may not even require the second stage - an output which verifies respected grammar may be enough.
What's more, tiny programs may bundle the whole tokenizer and parser to do it all at once.


IN SHORT:

Tokenizer -> holds tools for identifying tokens   --> (special encoding-related preprocessing is possible beforehand)
             performs token identification and inupt cleaning for larger programs

Parsing -> checks that token sequence respects the grammar (CPT)
           forms AST from the CPT
           passes on the format for execution, or immediatly performs exectution.

... 


MORE SEMANTICS AFFECTING PROGRAM DESIGN: (in drafting / incomplete)

Conditions - are about branching based on external state (the condition alone doesn't allow you to go back). Conditions are a form of prediction (pre-emption, foresight, etc)
  because to even write a condition means the programmer has predicted a probable occurrence and has developed contingencies in response. Also, a condition is somewhat a 
  sensor in itself! It allow an external input to be evaluated and with this feedback can alter a response. When conditions are based on statistics rather than simple logic 
  they become more powerful. (Conditions are really interesting because they imply a lot more, even the concept of choice).

Loops - allow you to go back, oblivious to external state.

In terms of the object in question, over time its external state / environment will change: 
Thus, combining conditions and loops together allows branching to reoccur informed by a new external state...

We can never completely control an external state (though we may inform it - chaotic systems).
Irrespective of the condition placed...

...

The following prioritisation will help to design efficient grammar.
1) Decide on your verbs.
2) Use terse delimiters to inform verb sequence.
3) Use recursive "non-terminals" when possible.
   - You will still need to check the grammar for LL (left-to-left) and other ambiguities.
4) Apply techniques to improve human readability judiciously, if at all (e.g whitespaces, chars, words, etc).


